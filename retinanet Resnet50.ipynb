{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U albumentations\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from torchvision.models.detection import retinanet_resnet50_fpn_v2, RetinaNet_ResNet50_FPN_V2_Weights\n",
    "from torchvision.models.detection.retinanet import RetinaNetClassificationHead\n",
    "from functools import partial\n",
    "import torch.nn as nn\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.amp import GradScaler, autocast\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import random\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CocoDataset class\n",
    "class CocoDataset(torchvision.datasets.CocoDetection):\n",
    "    def __init__(self, root, annFile, transform=None):\n",
    "        super(CocoDataset, self).__init__(root, annFile)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = super(CocoDataset, self).__getitem__(index)\n",
    "        image_id = self.ids[index]\n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(\n",
    "                image=np.array(img),\n",
    "                bboxes=[ann[\"bbox\"] for ann in target],\n",
    "                labels=[ann[\"category_id\"] for ann in target],\n",
    "            )\n",
    "            img = transformed[\"image\"]\n",
    "            target = [\n",
    "                {\"bbox\": bbox, \"category_id\": label, \"image_id\": image_id}\n",
    "                for bbox, label in zip(transformed[\"bboxes\"], transformed[\"labels\"])\n",
    "            ]\n",
    "        else:\n",
    "            for ann in target:\n",
    "                ann[\"image_id\"] = image_id\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Albumentations transformations\n",
    "train_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(640, 640),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Rotate(limit=20),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.RandomGamma(p=0.5),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format=\"coco\", label_fields=[\"labels\"]),\n",
    ")\n",
    "\n",
    "val_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(640, 640),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format=\"coco\", label_fields=[\"labels\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "dataset_path = \"/kaggle/input/oil-palm-bunch-3910\"\n",
    "\n",
    "train_dataset = CocoDataset(\n",
    "    root=os.path.join(dataset_path, \"train\"),\n",
    "    annFile=os.path.join(dataset_path, \"train\", \"_annotations.coco.json\"),\n",
    "    transform=train_transform,\n",
    ")\n",
    "\n",
    "val_dataset = CocoDataset(\n",
    "    root=os.path.join(dataset_path, \"valid\"),\n",
    "    annFile=os.path.join(dataset_path, \"valid\", \"_annotations.coco.json\"),\n",
    "    transform=val_transform,\n",
    ")\n",
    "\n",
    "test_dataset = CocoDataset(\n",
    "    root=os.path.join(dataset_path, \"test\"),\n",
    "    annFile=os.path.join(dataset_path, \"test\", \"_annotations.coco.json\"),\n",
    "    transform=val_transform,\n",
    ")\n",
    "\n",
    "# Create data loaders\n",
    "def collate_fn(batch):\n",
    "    images = []\n",
    "    targets = []\n",
    "\n",
    "    for image, target in batch:\n",
    "        images.append(image)\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for ann in target:\n",
    "            bbox = ann[\"bbox\"]\n",
    "            boxes.append([bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]])\n",
    "            labels.append(ann[\"category_id\"])\n",
    "\n",
    "        target_dict = {\n",
    "            \"boxes\": torch.FloatTensor(boxes),\n",
    "            \"labels\": torch.LongTensor(labels),\n",
    "            \"image_id\": torch.tensor(\n",
    "                [ann[\"image_id\"] for ann in target][0] if target else 0\n",
    "            ),\n",
    "        }\n",
    "        targets.append(target_dict)\n",
    "\n",
    "    return images, targets\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_samples(dataset, num_samples=5):\n",
    "    fig, axs = plt.subplots(1, num_samples, figsize=(20, 5))\n",
    "    category_ids = dataset.coco.getCatIds()\n",
    "    category_names = {cat['id']: cat['name'] for cat in dataset.coco.loadCats(category_ids)}\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        category_id = category_ids[i % len(category_ids)]\n",
    "        img_ids = dataset.coco.getImgIds(catIds=[category_id])\n",
    "        img_id = random.choice(img_ids)\n",
    "        img_info = dataset.coco.loadImgs(img_id)[0]\n",
    "        ann_ids = dataset.coco.getAnnIds(imgIds=img_id, catIds=[category_id])\n",
    "        anns = dataset.coco.loadAnns(ann_ids)\n",
    "        \n",
    "        image = dataset.coco.loadImgs(img_id)[0]\n",
    "        image = dataset.coco.loadImgs(img_id)[0]\n",
    "        img_path = os.path.join(dataset.root, image['file_name'])\n",
    "        img = plt.imread(img_path)\n",
    "        \n",
    "        axs[i].imshow(img)\n",
    "        axs[i].axis('off')\n",
    "        \n",
    "        for ann in anns:\n",
    "            bbox = ann['bbox']\n",
    "            category_name = category_names[ann['category_id']]\n",
    "            rect = patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], linewidth=2, edgecolor='r', facecolor='none')\n",
    "            axs[i].add_patch(rect)\n",
    "            axs[i].text(bbox[0], bbox[1] - 10, category_name, color='red', fontsize=12, backgroundcolor='white')\n",
    "        \n",
    "        axs[i].set_title(f\"({chr(97 + i)})\", fontsize=16)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Visualize random 5 samples from different categories in the training dataset\n",
    "visualize_samples(train_dataset, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "num_classes = len(train_dataset.coco.getCatIds()) + 1\n",
    "\n",
    "# Define the model\n",
    "def load_model(num_classes=num_classes):\n",
    "    model = retinanet_resnet50_fpn_v2(\n",
    "        weights=RetinaNet_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "    )\n",
    "    num_anchors = model.head.classification_head.num_anchors\n",
    "    classification_head = RetinaNetClassificationHead(\n",
    "        in_channels=256,\n",
    "        num_anchors=num_anchors,\n",
    "        num_classes=num_classes,\n",
    "        norm_layer=partial(torch.nn.GroupNorm, 32)\n",
    "    )\n",
    "    classification_head.cls_logits = nn.Sequential(\n",
    "        classification_head.conv,\n",
    "        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.5),\n",
    "        classification_head.cls_logits\n",
    "    )\n",
    "    model.head.classification_head = classification_head\n",
    "    return model\n",
    "\n",
    "\n",
    "# Load the model\n",
    "model = load_model()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Optimize anchor boxes\n",
    "model.anchor_generator.sizes = ((16, 32, 64, 128, 256, 512),)\n",
    "model.anchor_generator.aspect_ratios = ((0.5, 1.0, 2.0),) * len(model.anchor_generator.sizes)\n",
    "\n",
    "# Training setup\n",
    "num_epochs = 50\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics calculation\n",
    "def calculate_detection_metrics(coco_eval):\n",
    "    # Get precision and recall arrays from COCO evaluation\n",
    "    precision = coco_eval.eval['precision']\n",
    "    recall = coco_eval.eval['recall']\n",
    "    \n",
    "    # Get precision and recall at IoU=0.5 (first index)\n",
    "    precision_at_iou50 = precision[0, :, :, 0, -1]  # IoU=0.5, all categories, all areas\n",
    "    recall_at_iou50 = recall[0, :, 0]  # IoU=0.5, all categories\n",
    "    \n",
    "    # Calculate mean precision and recall\n",
    "    mean_precision = np.mean(precision_at_iou50[precision_at_iou50 > -1])\n",
    "    mean_recall = np.mean(recall_at_iou50[recall_at_iou50 > -1])\n",
    "    \n",
    "    # Calculate True Positives (TP), False Positives (FP), and False Negatives (FN)\n",
    "    TP = np.sum(precision_at_iou50 > 0)  # Number of true positives\n",
    "    FP = np.sum(precision_at_iou50 == 0)  # Number of false positives\n",
    "    FN = np.sum(recall_at_iou50 == 0)  # Number of false negatives\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = TP / (TP + FP + FN + 1e-6)\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    if mean_precision + mean_recall > 0:\n",
    "        f1_score = 2 * (mean_precision * mean_recall) / (mean_precision + mean_recall)\n",
    "    else:\n",
    "        f1_score = 0.0\n",
    "    \n",
    "    return accuracy, f1_score\n",
    "\n",
    "# Define function to calculate metrics\n",
    "def calculate_metrics(model, data_loader, device):\n",
    "    model.eval()\n",
    "    coco_gt = data_loader.dataset.coco\n",
    "    coco_dt = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(data_loader, desc=\"Validation\", unit=\"batch\")\n",
    "        \n",
    "        for images, targets in progress_bar:\n",
    "            images = [img.to(device) for img in images]\n",
    "            outputs = model(images)\n",
    "            \n",
    "            for i, output in enumerate(outputs):\n",
    "                boxes = output['boxes'].cpu()\n",
    "                scores = output['scores'].cpu() \n",
    "                labels = output['labels'].cpu()\n",
    "                \n",
    "                image_id = targets[i]['image_id'].item()\n",
    "                \n",
    "                for box, score, label in zip(boxes, scores, labels):\n",
    "                    coco_dt.append({\n",
    "                        'image_id': image_id,\n",
    "                        'category_id': label.item(),\n",
    "                        'bbox': [box[0].item(), box[1].item(), \n",
    "                                box[2].item() - box[0].item(),\n",
    "                                box[3].item() - box[1].item()],\n",
    "                        'score': score.item()\n",
    "                    })\n",
    "    \n",
    "    if len(coco_dt) == 0:\n",
    "        return 0.0, 0.0, 0.0, 0.0, 0.0\n",
    "    \n",
    "    coco_eval = COCOeval(coco_gt, coco_gt.loadRes(coco_dt), 'bbox')\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "    \n",
    "    # Extract metrics\n",
    "    mAP = coco_eval.stats[0]  # mAP@IoU=0.50:0.95\n",
    "    precision = coco_eval.stats[1]  # mAP@IoU=0.50\n",
    "    recall = coco_eval.stats[8]  # AR@IoU=0.50:0.95\n",
    "    \n",
    "    # Calculate accuracy and F1 using the new method\n",
    "    accuracy, f1_score = calculate_detection_metrics(coco_eval)\n",
    "    \n",
    "    return mAP, precision, recall, f1_score, accuracy\n",
    "\n",
    "# Define label smoothing function\n",
    "def smooth_labels(labels, num_classes, smoothing=0.1):\n",
    "    confidence = 1.0 - smoothing\n",
    "    label_shape = torch.Size((labels.size(0), num_classes))\n",
    "    with torch.no_grad():\n",
    "        smooth_labels = torch.full(size=label_shape, fill_value=smoothing / (num_classes - 1), device=labels.device)\n",
    "        smooth_labels.scatter_(1, labels.data.unsqueeze(1), confidence)\n",
    "    return smooth_labels\n",
    "\n",
    "# Initialize GradScaler\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Training loop\n",
    "metrics_history = {\n",
    "    \"train_loss\": [],\n",
    "    \"mAP\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1_score\": [],\n",
    "    \"accuracy\": [],\n",
    "}\n",
    "\n",
    "best_map = 0\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "patience = 5\n",
    "patience_counter = 0\n",
    "accumulation_steps = 4\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    progress_bar = tqdm(\n",
    "        train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\"\n",
    "    )\n",
    "\n",
    "    for i, (images, targets) in enumerate(progress_bar):\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        with autocast(device_type=\"cuda\" if torch.cuda.is_available() else \"cpu\"):\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "            loss = losses / accumulation_steps\n",
    "\n",
    "        # Apply label smoothing\n",
    "        for target in targets:\n",
    "            target[\"labels\"] = smooth_labels(target[\"labels\"], num_classes)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        train_loss += losses.item()\n",
    "        progress_bar.set_postfix(loss=losses.item())\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    avg_loss = train_loss / len(train_loader)\n",
    "    mAP, precision, recall, f1_score, accuracy = calculate_metrics(model, val_loader, device)\n",
    "\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Training Loss: {avg_loss:.4f}\")\n",
    "    print(f\"mAP: {mAP:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\\n\")\n",
    "\n",
    "    metrics_history[\"train_loss\"].append(avg_loss)\n",
    "    metrics_history[\"mAP\"].append(mAP)\n",
    "    metrics_history[\"precision\"].append(precision)\n",
    "    metrics_history[\"recall\"].append(recall)\n",
    "    metrics_history[\"f1_score\"].append(f1_score)\n",
    "    metrics_history[\"accuracy\"].append(accuracy)\n",
    "\n",
    "    if mAP > best_map:\n",
    "        best_map = mAP\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "model.load_state_dict(best_model_wts)\n",
    "torch.save(model.state_dict(), \"retinanet_resnet50_best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation on test set\n",
    "test_mAP, test_precision, test_recall, test_f1, test_accuracy = calculate_metrics(model, test_loader, device)\n",
    "\n",
    "print(\"\\nTest Set Results:\")\n",
    "print(f\"mAP: {test_mAP:.4f}\")\n",
    "print(f\"Precision: {test_precision:.4f}\")\n",
    "print(f\"Recall: {test_recall:.4f}\")\n",
    "print(f\"F1 Score: {test_f1:.4f}\")\n",
    "print(f\"Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_confusion_matrix(model, data_loader, device, confidence_threshold=0.5, iou_threshold=0.5):\n",
    "    model.eval()\n",
    "    categories = data_loader.dataset.coco.cats\n",
    "    num_classes = len(categories)\n",
    "    \n",
    "    # Initialize confusion matrix\n",
    "    confusion_mat = np.zeros((num_classes, num_classes))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(data_loader, desc=\"Calculating Confusion Matrix\"):\n",
    "            images = [img.to(device) for img in images]\n",
    "            \n",
    "            # Get predictions\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Process each image in the batch\n",
    "            for img_idx, output in enumerate(outputs):\n",
    "                # Get ground truth boxes and labels\n",
    "                gt_boxes = targets[img_idx]['boxes'].cpu().numpy()\n",
    "                gt_labels = targets[img_idx]['labels'].cpu().numpy()\n",
    "                \n",
    "                # Get predicted boxes, scores, and labels\n",
    "                pred_boxes = output['boxes'].cpu().numpy()\n",
    "                pred_scores = output['scores'].cpu().numpy()\n",
    "                pred_labels = output['labels'].cpu().numpy()\n",
    "                \n",
    "                # Filter predictions by confidence threshold\n",
    "                mask = pred_scores >= confidence_threshold\n",
    "                pred_boxes = pred_boxes[mask]\n",
    "                pred_labels = pred_labels[mask]\n",
    "                \n",
    "                # Calculate IoU between all predicted and ground truth boxes\n",
    "                for gt_idx, gt_box in enumerate(gt_boxes):\n",
    "                    gt_label = gt_labels[gt_idx]\n",
    "                    \n",
    "                    if len(pred_boxes) > 0:\n",
    "                        # Calculate IoU for all predictions\n",
    "                        ious = bbox_iou(gt_box, pred_boxes)\n",
    "                        max_iou_idx = np.argmax(ious)\n",
    "                        \n",
    "                        if ious[max_iou_idx] >= iou_threshold:\n",
    "                            # True Positive\n",
    "                            pred_label = pred_labels[max_iou_idx]\n",
    "                            confusion_mat[gt_label-1][pred_label-1] += 1\n",
    "                        else:\n",
    "                            # False Negative\n",
    "                            confusion_mat[gt_label-1][-1] += 1\n",
    "                    else:\n",
    "                        # False Negative\n",
    "                        confusion_mat[gt_label-1][-1] += 1\n",
    "                \n",
    "                # Count False Positives\n",
    "                if len(pred_boxes) > 0:\n",
    "                    for pred_label, pred_box in zip(pred_labels, pred_boxes):\n",
    "                        if not np.any(bbox_iou(pred_box, gt_boxes) >= iou_threshold):\n",
    "                            confusion_mat[-1][pred_label-1] += 1\n",
    "    \n",
    "    return confusion_mat\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    Calculate IoU between box1 and box2 or arrays of boxes\n",
    "    \"\"\"\n",
    "    if box2.ndim == 1:\n",
    "        box2 = box2[np.newaxis, :]\n",
    "    \n",
    "    # Calculate intersection\n",
    "    x1 = np.maximum(box1[0], box2[:, 0])\n",
    "    y1 = np.maximum(box1[1], box2[:, 1])\n",
    "    x2 = np.minimum(box1[2], box2[:, 2])\n",
    "    y2 = np.minimum(box1[3], box2[:, 3])\n",
    "    \n",
    "    intersection = np.maximum(0, x2 - x1) * np.maximum(0, y2 - y1)\n",
    "    \n",
    "    # Calculate areas\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[:, 2] - box2[:, 0]) * (box2[:, 3] - box2[:, 1])\n",
    "    \n",
    "    # Calculate union\n",
    "    union = box1_area + box2_area - intersection\n",
    "    \n",
    "    return intersection / (union + 1e-7)\n",
    "\n",
    "def plot_confusion_matrix(confusion_mat, categories):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix with proper labels and styling\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Get category names\n",
    "    category_names = [cat['name'] for cat in categories.values()]\n",
    "    category_names.append('Background')  # Add background class\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(\n",
    "        confusion_mat,\n",
    "        annot=True,\n",
    "        fmt='.0f',\n",
    "        cmap='Blues',\n",
    "        xticklabels=category_names,\n",
    "        yticklabels=category_names\n",
    "    )\n",
    "    \n",
    "    plt.title('Object Detection Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Ground Truth')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Calculate and plot confusion matrix\n",
    "def analyze_detection_performance(model, data_loader, device):\n",
    "    # Calculate confusion matrix\n",
    "    confusion_mat = calculate_confusion_matrix(\n",
    "        model, \n",
    "        data_loader, \n",
    "        device,\n",
    "        confidence_threshold=0.5,\n",
    "        iou_threshold=0.5\n",
    "    )\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(confusion_mat, data_loader.dataset.coco.cats)\n",
    "    \n",
    "    # Calculate per-class metrics\n",
    "    num_classes = len(data_loader.dataset.coco.cats)\n",
    "    \n",
    "    print(\"\\nPer-class Performance Metrics:\")\n",
    "    print(\"-----------------------------\")\n",
    "    \n",
    "    for cat_id, cat_info in data_loader.dataset.coco.cats.items():\n",
    "        idx = cat_id - 1  # Adjust for 0-based indexing\n",
    "        \n",
    "        # Calculate metrics\n",
    "        tp = confusion_mat[idx][idx]\n",
    "        fp = np.sum(confusion_mat[:, idx]) - tp\n",
    "        fn = np.sum(confusion_mat[idx, :]) - tp\n",
    "        \n",
    "        precision = tp / (tp + fp + 1e-7)\n",
    "        recall = tp / (tp + fn + 1e-7)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall + 1e-7)\n",
    "        \n",
    "        print(f\"\\nClass: {cat_info['name']}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "# Add this after your model evaluation code\n",
    "print(\"\\nAnalyzing detection performance...\")\n",
    "analyze_detection_performance(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics_history):\n",
    "    epochs = range(1, len(metrics_history[\"train_loss\"]) + 1)\n",
    "\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(epochs, metrics_history[\"train_loss\"], \"b-\", label=\"Training Loss\")\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.text(-0.1, 1.1, \"(a)\", transform=plt.gca().transAxes, fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Plot mAP\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(epochs, metrics_history[\"mAP\"], \"r-\", label=\"mAP\")\n",
    "    plt.title(\"Mean Average Precision\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"mAP\")\n",
    "    plt.legend()\n",
    "    plt.text(-0.1, 1.1, \"(b)\", transform=plt.gca().transAxes, fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Plot Precision and Recall\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.plot(epochs, metrics_history[\"precision\"], \"g-\", label=\"Precision\")\n",
    "    plt.plot(epochs, metrics_history[\"recall\"], \"y-\", label=\"Recall\")\n",
    "    plt.title(\"Precision and Recall\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.legend()\n",
    "    plt.text(-0.1, 1.1, \"(c)\", transform=plt.gca().transAxes, fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Plot F1 Score\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(epochs, metrics_history[\"f1_score\"], \"m-\", label=\"F1 Score\")\n",
    "    plt.title(\"F1 Score\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.legend()\n",
    "    plt.text(-0.1, 1.1, \"(d)\", transform=plt.gca().transAxes, fontsize=16, fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the metrics\n",
    "plot_metrics(metrics_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import random\n",
    "import matplotlib.patches as patches\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torch.nn as nn\n",
    "import torchvision.ops as ops\n",
    "from torchvision.models.detection import retinanet_resnet50_fpn_v2, RetinaNet_ResNet50_FPN_V2_Weights\n",
    "from torchvision.models.detection.retinanet import RetinaNetClassificationHead\n",
    "from functools import partial\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# Define the CocoDataset class\n",
    "class CocoDataset(torchvision.datasets.CocoDetection):\n",
    "    def __init__(self, root, annFile, transform=None):\n",
    "        super(CocoDataset, self).__init__(root, annFile)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = super(CocoDataset, self).__getitem__(index)\n",
    "        image_id = self.ids[index]\n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(\n",
    "                image=np.array(img),\n",
    "                bboxes=[ann[\"bbox\"] for ann in target],\n",
    "                labels=[ann[\"category_id\"] for ann in target],\n",
    "            )\n",
    "            img = transformed[\"image\"]\n",
    "            target = [\n",
    "                {\"bbox\": bbox, \"category_id\": label, \"image_id\": image_id}\n",
    "                for bbox, label in zip(transformed[\"bboxes\"], transformed[\"labels\"])\n",
    "            ]\n",
    "        else:\n",
    "            for ann in target:\n",
    "                ann[\"image_id\"] = image_id\n",
    "        return img, target\n",
    "\n",
    "\n",
    "# Define Albumentations transformations\n",
    "val_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(640, 640),\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        ToTensorV2(),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format=\"coco\", label_fields=[\"labels\"]),\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "dataset_path = \"/kaggle/input/oil-palm-bunch-3910\"\n",
    "\n",
    "test_dataset = CocoDataset(\n",
    "    root=os.path.join(dataset_path, \"test\"),\n",
    "    annFile=os.path.join(dataset_path, \"test\", \"_annotations.coco.json\"),\n",
    "    transform=val_transform,\n",
    ")\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "def collate_fn(batch):\n",
    "    images = []\n",
    "    targets = []\n",
    "\n",
    "    for image, target in batch:\n",
    "        images.append(image)\n",
    "\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        for ann in target:\n",
    "            bbox = ann[\"bbox\"]\n",
    "            boxes.append([bbox[0], bbox[1], bbox[0] + bbox[2], bbox[1] + bbox[3]])\n",
    "            labels.append(ann[\"category_id\"])\n",
    "\n",
    "        target_dict = {\n",
    "            \"boxes\": torch.FloatTensor(boxes),\n",
    "            \"labels\": torch.LongTensor(labels),\n",
    "            \"image_id\": torch.tensor(\n",
    "                [ann[\"image_id\"] for ann in target][0] if target else 0\n",
    "            ),\n",
    "        }\n",
    "        targets.append(target_dict)\n",
    "\n",
    "    return images, targets\n",
    "\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "num_classes = len(test_dataset.coco.getCatIds()) + 1\n",
    "\n",
    "\n",
    "# Define the model\n",
    "def load_model(num_classes=num_classes):\n",
    "    model = retinanet_resnet50_fpn_v2(\n",
    "        weights=RetinaNet_ResNet50_FPN_V2_Weights.DEFAULT\n",
    "    )\n",
    "    num_anchors = model.head.classification_head.num_anchors\n",
    "    classification_head = RetinaNetClassificationHead(\n",
    "        in_channels=256,\n",
    "        num_anchors=num_anchors,\n",
    "        num_classes=num_classes,\n",
    "        norm_layer=partial(torch.nn.GroupNorm, 32)\n",
    "    )\n",
    "    classification_head.cls_logits = nn.Sequential(\n",
    "        classification_head.conv,\n",
    "        nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=0.5),\n",
    "        classification_head.cls_logits\n",
    "    )\n",
    "    model.head.classification_head = classification_head\n",
    "    return model\n",
    "\n",
    "\n",
    "# Load the best model\n",
    "model = load_model(num_classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(\n",
    "    torch.load(\"retinanet_resnet50_best_model.pth\", weights_only=True, map_location=device)\n",
    ")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "# Function to denormalize images\n",
    "def denormalize(image, mean, std):\n",
    "    image = image.permute(1, 2, 0).cpu().numpy()\n",
    "    image = (image * std + mean) * 255\n",
    "    image = image.astype(np.uint8)\n",
    "    return image\n",
    "\n",
    "\n",
    "# Function to visualize predictions\n",
    "def visualize_predictions(\n",
    "    dataset, model, device, num_samples=5, confidence_threshold=0.5, iou_threshold=0.5\n",
    "):\n",
    "    fig, axs = plt.subplots(1, num_samples, figsize=(20, 5))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "    category_ids = dataset.coco.getCatIds()\n",
    "    selected_images = []\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        category_id = category_ids[i % len(category_ids)]\n",
    "        img_ids = dataset.coco.getImgIds(catIds=[category_id])\n",
    "        img_id = random.choice(img_ids)\n",
    "        selected_images.append(img_id)\n",
    "\n",
    "    for i, img_id in enumerate(selected_images):\n",
    "        img_info = dataset.coco.loadImgs(img_id)[0]\n",
    "        ann_ids = dataset.coco.getAnnIds(imgIds=img_id)\n",
    "        anns = dataset.coco.loadAnns(ann_ids)\n",
    "        img_path = os.path.join(dataset.root, img_info['file_name'])\n",
    "        img = plt.imread(img_path)\n",
    "        \n",
    "        image, target = dataset[dataset.ids.index(img_id)]\n",
    "        image = image.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model([image])[0]\n",
    "\n",
    "        # Apply NMS\n",
    "        keep = ops.nms(output[\"boxes\"], output[\"scores\"], iou_threshold)\n",
    "        output[\"boxes\"] = output[\"boxes\"][keep]\n",
    "        output[\"scores\"] = output[\"scores\"][keep]\n",
    "        output[\"labels\"] = output[\"labels\"][keep]\n",
    "\n",
    "        image = denormalize(image, mean, std)\n",
    "        axs[i].imshow(image)\n",
    "        axs[i].axis(\"off\")\n",
    "\n",
    "        # Plot ground truth\n",
    "        for ann in target:\n",
    "            bbox = ann[\"bbox\"]\n",
    "            category_id = ann[\"category_id\"]\n",
    "            category_name = dataset.coco.cats[category_id][\"name\"]\n",
    "            rect = patches.Rectangle(\n",
    "                (bbox[0], bbox[1]),\n",
    "                bbox[2],\n",
    "                bbox[3],\n",
    "                linewidth=2,\n",
    "                edgecolor=\"g\",\n",
    "                facecolor=\"none\",\n",
    "                label=\"Ground Truth\",\n",
    "            )\n",
    "            axs[i].add_patch(rect)\n",
    "            axs[i].text(\n",
    "                bbox[0],\n",
    "                bbox[1] + bbox[3] + 10,\n",
    "                category_name,\n",
    "                color=\"green\",\n",
    "                fontsize=12,\n",
    "                backgroundcolor=\"white\",\n",
    "            )\n",
    "\n",
    "        # Plot predictions\n",
    "        for box, score, label in zip(\n",
    "            output[\"boxes\"], output[\"scores\"], output[\"labels\"]\n",
    "        ):\n",
    "            if score >= confidence_threshold:\n",
    "                bbox = box.cpu().numpy()\n",
    "                category_name = dataset.coco.cats[label.item()][\"name\"]\n",
    "                rect = patches.Rectangle(\n",
    "                    (bbox[0], bbox[1]),\n",
    "                    bbox[2] - bbox[0],\n",
    "                    bbox[3] - bbox[1],\n",
    "                    linewidth=2,\n",
    "                    edgecolor=\"r\",\n",
    "                    facecolor=\"none\",\n",
    "                    label=\"Prediction\",\n",
    "                )\n",
    "                axs[i].add_patch(rect)\n",
    "                axs[i].text(\n",
    "                    bbox[0],\n",
    "                    bbox[1] - 10,\n",
    "                    f\"{category_name}: {score:.2f}\",\n",
    "                    color=\"red\",\n",
    "                    fontsize=12,\n",
    "                    backgroundcolor=\"white\",\n",
    "                )\n",
    "\n",
    "        # Add legend\n",
    "        handles, labels = axs[i].get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "        axs[i].legend(\n",
    "            by_label.values(), by_label.keys(), loc=\"upper right\", fontsize=10\n",
    "        )\n",
    "\n",
    "        # Add subplot tag\n",
    "        axs[i].set_title(f\"({chr(97 + i)})\", fontsize=16)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize predictions with 5 random samples from the validation dataset with a confidence threshold of 0.5\n",
    "visualize_predictions(\n",
    "    test_dataset,\n",
    "    model,\n",
    "    device,\n",
    "    num_samples=5,\n",
    "    confidence_threshold=0.5,\n",
    "    iou_threshold=0.5,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
